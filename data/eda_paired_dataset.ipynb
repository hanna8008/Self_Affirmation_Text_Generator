{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for Paired Dataset (paired_affirmations.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from transformers import GPT2TokenizerFast\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"paired_affirmations.csv\")\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Missing or Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull.sum()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_len'] = df['Input'].astype(str).apply(len)\n",
    "df['output_len'] = df['Output'].astype(str).apply(len)\n",
    "\n",
    "df[['input_len', 'output_len']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['input_len'], kde=True, bins=30).set(title=\"Input Length Distribution\")\n",
    "plt.savefig(\"../results/eda/input_length_distribution.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(df['output_len'], kde=True, bins=30).set(title=\"Output Length Distribution\")\n",
    "plt.savefig(\"../results/eda/output_length_distribution.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Distrbiutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emotion_Label'].value_counts().plot(kind='bar', title=\"Emotion Label Distribution\")\n",
    "plt.savefig(\"../results/eda/emotion_label_distribution.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "df['Affirmation_Tag'].value_counts().plot(kind='bar', title\"Affirmation Tag Distribution\")\n",
    "plt.savefig(\"../results/eda/affirmation_tag_distribution.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = \" \".join(df['Input'].astype(str).tolist())\n",
    "input_wc = WordCloud(width=800, height=400, background_color='white').generate(all_inputs)\n",
    "\n",
    "plt.imshow(input_wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud - Input Texts\")\n",
    "plt.savefig(\"../results/eda/wordCloud_input_texts.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "all_inputs = \" \".join(df['Output'].astype(str).tolist())\n",
    "input_wc = WordCloud(width=800, height=400, background_color='white').generate(all_inputs)\n",
    "\n",
    "plt.imshow(input_wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud - Output Texts\")\n",
    "plt.savefig(\"../results/eda/wordCloud_output_texts.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag vs. Input/Output Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='Affirmation_Tag', y='input_len')\n",
    "plt.title(\"Input Length by Affirmation Tag\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"../results/eda/input_length_by_affirmation_tag.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Combined Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_len'] = df['input_len'] + df['output_len']\n",
    "sns.histplot(df['total_len'], bins=30, kde=True)\n",
    "plt.title(\"Total Input + Output Length Distribution\")\n",
    "plt.savefig(\"../results/eda/total_input_output_length_distribution.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Emotions vs. Affirmation_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = pd.crosstab(df['Emotion_Label'], df['Affirmation_Tag'])\n",
    "sns.heatmap(heatmap_dadta, annot=True, fmt='d', cmap=\"Y1GnBu\")\n",
    "plt.title(\"Emotion vs. Affirmation Tag Frequency\")\n",
    "plt.savefig(\"../results/eda/emotion_vs_tag_heatmap.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length Threshold Coverage\n",
    "How many pairs exceed 256 or 512 tokens (important for GPT2)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_len'] = df['input_len'] + df['output_len']\n",
    "print(\"Pairs >256 characters:\", (df['total_len'] > 256).sum())\n",
    "print(\"Pairs >512 characters:\", (df['total_len'] > 512).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Length Analysis (GPT-2 Limit Awareness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_prerained(\"gpt2\")\n",
    "\n",
    "df['num_tokens_input'] = df['Input'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df['num_tokens_output'] = df['Output'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df['total_tokens'] = df['num_tokens_input'] + df['num_tokens_output']\n",
    "\n",
    "# Histogram of total tokens\n",
    "sns.histplot(df['total_tokens'], bins=30, kde=True)\n",
    "plt.title(\"Total Token Count per Input+Output Pair\")\n",
    "plt.savefig(\"../results/eda/total_token_distribution.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Pairs over 512 tokens: \", (df['total_tokens'] > 512)sum())\n",
    "print(\"Pairs over 1024 tokens (GPT-2 limit): \", (df['total_tokens'] > 1024).sum())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
